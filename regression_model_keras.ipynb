{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349bdab0-e7c9-492e-aebf-a2c000277d96",
   "metadata": {},
   "source": [
    "# Regression model with Keras\n",
    "## A. Build a baseline model (5 marks)\n",
    "- Define a function baseline_model to create the baseline neural network model with one hidden layer of 10 nodes and ReLU activation.\n",
    "- Initialize an empty list mse_list to store the mean squared errors calculated in each iteration.\n",
    "- Loop 50 times, in each iteration:\n",
    "  - Split the data into training and test sets.\n",
    "  - Build and train the model on the training data.\n",
    "  - Evaluate the model on the test data and calculate the mean squared error.\n",
    "  - Append the mean squared error to the mse_list.\n",
    "- Calculate the mean and standard deviation of the mean squared errors from the list and print them out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bc3b0-91a2-4e12-86e6-562b8c46f390",
   "metadata": {},
   "source": [
    "Cement data\n",
    "\n",
    "The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:\n",
    "\n",
    "1. Cement\n",
    "\n",
    "2. Blast Furnace Slag\n",
    "\n",
    "3. Fly Ash\n",
    "\n",
    "4. Water\n",
    "\n",
    "5. Superplasticizer\n",
    "\n",
    "6. Coarse Aggregate\n",
    "\n",
    "7. Fine Aggregate\n",
    "\n",
    "8. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7840172-640d-421b-9e3a-e6971fd83369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2f3ee9-fa9d-41ca-b431-13100cdaef82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0f3163-af3d-488a-9ecd-b8c48fa46945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X = concrete_data.drop(columns=['Strength'])\n",
    "y = concrete_data['Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109c46fb-4c4f-43ae-99ce-b764751ea58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the baseline regression model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b8ed34-5406-4e0d-962d-22077ea78010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store mean squared errors\n",
    "mse_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aec18296-3911-4202-a6a4-5fe5baba7166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:977: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:964: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 08:22:39.388348: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-02-08 08:22:39.393634: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394280000 Hz\n",
      "2024-02-08 08:22:39.394443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f1a4b68550 executing computations on platform Host. Devices:\n",
      "2024-02-08 08:22:39.394507: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2024-02-08 08:22:39.476391: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    }
   ],
   "source": [
    "# Repeat steps 1 - 3, 50 times\n",
    "for _ in range(50):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = baseline_model()\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1401490d-8692-43aa-ae96-463a7fdd3fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of mean squared errors\n",
    "mean_mse = np.mean(mse_list)\n",
    "std_mse = np.std(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "855ef512-0cb4-45f2-af30-6ae94f69bce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 50 MSE from our model:\n",
      "[1449.5564794588665,\n",
      " 124.81163492182192,\n",
      " 130.29771170313742,\n",
      " 118.29256733173607,\n",
      " 139.51851486946015,\n",
      " 221.614117210219,\n",
      " 130.24801397482614,\n",
      " 153.419446776072,\n",
      " 100.25656116186184,\n",
      " 99.02090544033874,\n",
      " 1818.977193926198,\n",
      " 117.19773879515962,\n",
      " 175.15560079891628,\n",
      " 76.34180551870477,\n",
      " 332.8392820096209,\n",
      " 591.2228649748192,\n",
      " 105.99073926054807,\n",
      " 125.00643714692251,\n",
      " 620.5891305043426,\n",
      " 892.9708182921638,\n",
      " 109.48945812619155,\n",
      " 519.7431042269554,\n",
      " 147.3800970367127,\n",
      " 151.77851967548673,\n",
      " 264.29953969090406,\n",
      " 109.2221610115333,\n",
      " 142.66981638586824,\n",
      " 1168.857807707891,\n",
      " 450.17123486883315,\n",
      " 349.86013594943984,\n",
      " 239.2755845969015,\n",
      " 93.35491152256016,\n",
      " 351.55826705974243,\n",
      " 157.41471162887916,\n",
      " 596.0653165278425,\n",
      " 130.80606682529276,\n",
      " 145.39627279033206,\n",
      " 113.3491761709147,\n",
      " 451.5830437595016,\n",
      " 111.77809898441139,\n",
      " 180.5753125452564,\n",
      " 421.22247749276755,\n",
      " 140.56345606416264,\n",
      " 117.58563127696118,\n",
      " 1247.5077485139846,\n",
      " 1772.2532996937737,\n",
      " 431.7940444342002,\n",
      " 130.90813080655877,\n",
      " 160.91285240003677,\n",
      " 127.99117435612217]\n",
      "Mean Squared Error (MSE) across 50 runs: 361.1739003241151\n",
      "Standard Deviation of MSE across 50 runs: 422.5422391812447\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "print(\"The 50 MSE from our model:\")\n",
    "pp.pprint(mse_list)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) across 50 runs:\", mean_mse)\n",
    "print(\"Standard Deviation of MSE across 50 runs:\", std_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14468dbb-b2bd-4f50-95b9-bd3ba7bce8b4",
   "metadata": {},
   "source": [
    "## B. Normalize the data (5 marks) \n",
    "\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89088c1d-e48d-4525-8961-63f12464e505",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) across 50 runs with normalized data: 370.48961542065786\n",
      "Standard Deviation of MSE across 50 runs with normalized data: 123.3840618756732\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Define the baseline regression model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_normalized.shape[1],)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Initialize a list to store mean squared errors\n",
    "mse_list_normalized = []\n",
    "\n",
    "# Repeat steps 1 - 3, 50 times\n",
    "for _ in range(50):\n",
    "    # Split the normalized data into training and test sets\n",
    "    X_train_norm, X_test_norm, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = baseline_model()\n",
    "    model.fit(X_train_norm, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the normalized test data\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_normalized.append(mse)\n",
    "\n",
    "# Calculate mean and standard deviation of mean squared errors\n",
    "mean_mse_normalized = np.mean(mse_list_normalized)\n",
    "std_mse_normalized = np.std(mse_list_normalized)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) across 50 runs with normalized data:\", mean_mse_normalized)\n",
    "print(\"Standard Deviation of MSE across 50 runs with normalized data:\", std_mse_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf68fb5-2a94-43a9-acd5-2ab8922a4017",
   "metadata": {},
   "source": [
    "## C. Increase the number of epochs (5 marks)\n",
    "\n",
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11ee6c40-130b-4f3e-92cd-950efd782989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) across 50 runs with normalized data and 100 epochs: 164.51256072361764\n",
      "Standard Deviation of MSE across 50 runs with normalized data and 100 epochs: 17.33833984634371\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X = concrete_data.drop(columns=['Strength'])\n",
    "y = concrete_data['Strength']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Define the baseline regression model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X_normalized.shape[1],)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Initialize a list to store mean squared errors\n",
    "mse_list_normalized_100_epochs = []\n",
    "\n",
    "# Repeat steps 1 - 3, 50 times\n",
    "for _ in range(50):\n",
    "    # Split the normalized data into training and test sets\n",
    "    X_train_norm, X_test_norm, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
    "    \n",
    "    # Build and train the model with 100 epochs\n",
    "    model = baseline_model()\n",
    "    model.fit(X_train_norm, y_train, epochs=100, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the normalized test data\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_normalized_100_epochs.append(mse)\n",
    "\n",
    "# Calculate mean and standard deviation of mean squared errors\n",
    "mean_mse_normalized_100_epochs = np.mean(mse_list_normalized_100_epochs)\n",
    "std_mse_normalized_100_epochs = np.std(mse_list_normalized_100_epochs)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) across 50 runs with normalized data and 100 epochs:\", mean_mse_normalized_100_epochs)\n",
    "print(\"Standard Deviation of MSE across 50 runs with normalized data and 100 epochs:\", std_mse_normalized_100_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506d8ab-22ce-4561-9d85-b1b277049b0e",
   "metadata": {},
   "source": [
    "## D. Increase the number of hidden layers (5 marks)\n",
    "\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c58f33-3513-4468-8f82-6e35071ffb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE) across 50 runs for the updated model: 117.38601020983754\n",
      "Standard Deviation of MSE across 50 runs for the updated model: 45.92629442755122\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into features (X) and target (y)\n",
    "X = concrete_data.drop(columns=['Strength'])\n",
    "y = concrete_data['Strength']\n",
    "\n",
    "# Define the updated regression model with three hidden layers\n",
    "def updated_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Initialize a list to store mean squared errors\n",
    "mse_list_updated = []\n",
    "\n",
    "# Repeat steps 1 - 3, 50 times\n",
    "for _ in range(50):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Build and train the updated model\n",
    "    model = updated_model()\n",
    "    model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    \n",
    "    # Evaluate the updated model on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_list_updated.append(mse)\n",
    "\n",
    "# Calculate mean and standard deviation of mean squared errors for the updated model\n",
    "mean_mse_updated = np.mean(mse_list_updated)\n",
    "std_mse_updated = np.std(mse_list_updated)\n",
    "\n",
    "print(\"Mean Squared Error (MSE) across 50 runs for the updated model:\", mean_mse_updated)\n",
    "print(\"Standard Deviation of MSE across 50 runs for the updated model:\", std_mse_updated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80b47c-a394-4917-9a44-a3a05606d68d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Data Normalization (Part B vs. Part A):\n",
    "Normalizing the data slightly increased the mean squared error (from 361.17 to 370.49), but significantly reduced the standard deviation of the errors (from 422.54 to 123.38). This indicates that normalization helps to stabilize the model's performance across different runs.\n",
    "\n",
    "### Increased Epochs (Part C vs. Part B):\n",
    "Increasing the number of epochs from 50 to 100 resulted in a notable decrease in mean squared error (from 370.49 to 164.51) and a significant reduction in standard deviation (from 123.38 to 17.34). This suggests that training the model for more epochs allowed it to better capture the underlying patterns in the data, leading to improved performance and reduced variance.\n",
    "\n",
    "### Additional Hidden Layers (Part D vs. Part C):\n",
    "Adding three hidden layers with 10 nodes each further decreased the mean squared error (from 164.51 to 117.39) while increasing the standard deviation (from 17.34 to 45.93). This indicates that increasing the complexity of the model by adding more hidden layers improved the average performance, but also increased the variance or variability in the model's predictions across different runs.\n",
    "\n",
    "In summary, data normalization, increased epochs, and additional model complexity all contributed to improvements in the model's performance, as evidenced by the decreasing mean squared error. However, there's a trade-off between model complexity and stability, as increasing complexity (e.g., adding more hidden layers) can lead to higher variance in the model's predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
